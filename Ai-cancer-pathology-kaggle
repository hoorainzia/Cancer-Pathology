{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12395406,"sourceType":"datasetVersion","datasetId":7816412}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1.Importing Datasets","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms, datasets\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nimport numpy as np\nfrom torch.optim.lr_scheduler import StepLR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T08:56:16.295688Z","iopub.execute_input":"2025-07-15T08:56:16.295916Z","iopub.status.idle":"2025-07-15T08:56:16.301149Z","shell.execute_reply.started":"2025-07-15T08:56:16.295898Z","shell.execute_reply":"2025-07-15T08:56:16.300285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data loading & Visualization","metadata":{}},{"cell_type":"code","source":"class_names = [\"Normal\", \"Benign\", \"InSitu\", \"Invasive\"]  \nroot_dir = \"/kaggle/input/bach-a-microscopy-images/Photos\"  \n\nplt.figure(figsize=(15, 10))\nfor i, class_name in enumerate(class_names):\n    class_dir = os.path.join(root_dir, class_name)\n    sample_file = os.listdir(class_dir)[0]\n    img_path = os.path.join(class_dir, sample_file)\n    img = Image.open(img_path).convert('RGB')\n    plt.subplot(1, 4, i+1)\n    plt.imshow(img)\n    plt.title(f'{class_name}')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T08:56:16.301998Z","iopub.execute_input":"2025-07-15T08:56:16.302973Z","iopub.status.idle":"2025-07-15T08:56:17.925266Z","shell.execute_reply.started":"2025-07-15T08:56:16.302947Z","shell.execute_reply":"2025-07-15T08:56:17.924424Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Setting image sizes","metadata":{}},{"cell_type":"code","source":"def load_image(path, size=(224, 224)):\n    img = Image.open(path).convert('RGB')\n    img = img.resize(size)\n    img = np.array(img).astype(np.float32) / 255.0\n    img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n    img = np.transpose(img, (2, 0, 1))\n    return img\n# Added after load_image function\ntrain_augmentation = transforms.Compose([\n    transforms.ToPILImage(),  # Convert tensor to PIL\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(degrees=30),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n    transforms.RandomAutocontrast(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntest_augmentation = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T08:56:17.926507Z","iopub.execute_input":"2025-07-15T08:56:17.926865Z","iopub.status.idle":"2025-07-15T08:56:17.934086Z","shell.execute_reply.started":"2025-07-15T08:56:17.926835Z","shell.execute_reply":"2025-07-15T08:56:17.933398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Dataset preparation","metadata":{}},{"cell_type":"code","source":"images = []\nlabels = []\n#Loop to load images:\nfor label_idx, class_name in enumerate(class_names):\n    class_dir = os.path.join(root_dir, class_name)\n    for fname in os.listdir(class_dir):\n        if fname.endswith('.tif'):\n            img_path = os.path.join(class_dir, fname)\n            img = load_image(img_path)\n            images.append(img)\n            labels.append(label_idx)\n\nimages_tensor = torch.tensor(np.array(images), dtype=torch.float32)\nlabels_tensor = torch.tensor(labels, dtype=torch.long)\n\n# Split into training and test sets(80/20):\nX_train, X_test, y_train, y_test = train_test_split(\n    images_tensor, labels_tensor, \n    test_size=0.2, \n    random_state=42,\n    stratify=labels_tensor\n)\n\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\nprint(f\"Train size: {len(train_dataset)}\")\nprint(f\"Test size: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T08:56:17.935986Z","iopub.execute_input":"2025-07-15T08:56:17.936277Z","iopub.status.idle":"2025-07-15T08:56:32.841935Z","shell.execute_reply.started":"2025-07-15T08:56:17.936252Z","shell.execute_reply":"2025-07-15T08:56:32.841097Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Model Setup","metadata":{}},{"cell_type":"code","source":"#Mentioning Model for training\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.efficientnet_b0(pretrained=True)\n\n# Freezed feature extractor\nfor param in model.features.parameters():\n    param.requires_grad = False\n\n# Replaced classifier head\nnum_ftrs = model.classifier[1].in_features\nmodel.classifier = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(num_ftrs, 256),\n    nn.BatchNorm1d(256),\n    nn.ReLU(inplace=True),\n    nn.Dropout(0.5),\n    nn.Linear(256, 4)\n)\nmodel = model.to(device)\n\n# Training setup\nbatch_size = 25\nlearning_rate = 30e-4\nepochs = 40\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=learning_rate,\n    weight_decay=1e-4\n)\nscheduler = StepLR(optimizer, step_size=5, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T08:56:32.842817Z","iopub.execute_input":"2025-07-15T08:56:32.843189Z","iopub.status.idle":"2025-07-15T08:56:33.233811Z","shell.execute_reply.started":"2025-07-15T08:56:32.843171Z","shell.execute_reply":"2025-07-15T08:56:33.233056Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6.Training Loop","metadata":{}},{"cell_type":"code","source":"train_losses = []\ntrain_accs = []\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n# Looping over the batches of data:\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n# Calculating average loss and accuracy:\n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100 * correct / total\n    train_losses.append(epoch_loss)\n    train_accs.append(epoch_acc)\n    \n    print(f\"Epoch {epoch+1}/{epochs} â€” \"\n          f\"Loss: {epoch_loss:.4f}, \"\n          f\"Accuracy: {epoch_acc:.2f}%\")\n    \n    scheduler.step()\n#Finding average\naverage_acc = sum(train_accs) / len(train_accs)\naverage_loss = sum(train_losses) / len(train_losses)\n\nprint(\"\\n==============================\")\nprint(f\"Average Training Accuracy over {epochs} epochs: {average_acc:.2f}%\")\nprint(f\"Average Training Loss over {epochs} epochs: {average_loss:.4f}\")\n\n# Plot training history\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, marker='o')\nplt.title('Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accs, marker='o')\nplt.title('Training Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')  \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T08:56:33.234668Z","iopub.execute_input":"2025-07-15T08:56:33.235407Z","iopub.status.idle":"2025-07-15T08:56:52.94802Z","shell.execute_reply.started":"2025-07-15T08:56:33.235269Z","shell.execute_reply":"2025-07-15T08:56:52.947344Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Evaluation & Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# added this test evaluation block\ndef tta_predict(model, input_tensor):\n    # \"\"\"Test-Time Augmentation for robustness\"\"\"\n    # Original\n    outputs = model(input_tensor.unsqueeze(0))\n    # Horizontal flip\n    outputs += model(torch.flip(input_tensor, [2]).unsqueeze(0))\n    # Vertical flip\n    outputs += model(torch.flip(input_tensor, [1]).unsqueeze(0))\n    # Brightness adjustment\n    bright_img = torch.clamp(input_tensor * 1.3, 0, 1)\n    outputs += model(bright_img.unsqueeze(0))\n    # Dark adjustment\n    dark_img = torch.clamp(input_tensor * 0.7, 0, 1)\n    outputs += model(dark_img.unsqueeze(0))\n    \n    return outputs / 5.0\n# Updated evaluation\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs = inputs.to(device)\n        for i in range(inputs.size(0)):\n            output = tta_predict(model, inputs[i])\n            _, pred = torch.max(output, 1)\n            all_preds.append(pred.item())\n        all_labels.extend(labels.numpy())\n\nprint(\"Test Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=class_names))\n\n# Generating confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=class_names, \n            yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T08:56:52.948817Z","iopub.execute_input":"2025-07-15T08:56:52.949082Z","iopub.status.idle":"2025-07-15T08:56:56.547331Z","shell.execute_reply.started":"2025-07-15T08:56:52.949059Z","shell.execute_reply":"2025-07-15T08:56:56.546683Z"}},"outputs":[],"execution_count":null}]}